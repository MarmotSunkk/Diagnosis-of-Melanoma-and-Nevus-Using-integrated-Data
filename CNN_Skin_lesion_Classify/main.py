import torch
import torch.nn as nn
from net import vgg16
from torch.utils.data import DataLoader# extract data from datasets (small batches)
from data import *
'''Dataset'''
annotation_path='cls_train.txt'# Read the file generated by the dataset
with open(annotation_path,'r') as f:
    lines=f.readlines()
np.random.seed(10101)# function used to generate the specified random number
np.random.shuffle(lines)# data to be shuffled
np.random.seed(None)
num_val=int(len(lines)*0.2)# 1 out of 5 for test
num_train=len(lines)-num_val
# input image size
input_shape=[224,224]   # Import image size
train_data=DataGenerator(lines[:num_train],input_shape,True)
val_data=DataGenerator(lines[num_train:],input_shape,False)
val_len=len(val_data)
print(val_len)# Return test set length

"""Load data"""
gen_train=DataLoader(train_data,batch_size=4)#training set batch_size read small samples, specify how many samples to take each time
gen_test=DataLoader(val_data,batch_size=4)#test set reads small samples
'''Build a network'''
device=torch.device('cuda'if torch.cuda.is_available() else "cpu")
net=vgg16(True, progress=True,num_classes=2)#set categories for classification
net.to(device)
'''Selection of optimiser and tuning method for learning rate'''
lr=0.0001#define learning rate
optim=torch.optim.Adam(net.parameters(),lr=lr)#import network and learning rate
sculer=torch.optim.lr_scheduler.StepLR(optim,step_size=1)#read with step size 1
'''训练'''
epochs=10
for epoch in range(epochs):
    total_train=0 # total loss
    for data in gen_train:
        img,label=data
        with torch.no_grad():
            img =img.to(device)
            label=label.to(device)
        optim.zero_grad()
        output=net(img)
        train_loss=nn.CrossEntropyLoss()(output,label).to(device)
        train_loss.backward()#backpropagation
        optim.step()#optimiser update
        total_train+=train_loss #losses summed up
    sculer.step()
    total_test=0#total_loss
    total_accuracy=0#total_acc
    for data in gen_test:
        img,label =data
        with torch.no_grad():
            img=img.to(device)
            label=label.to(device)
            optim.zero_grad()# zero the gradient
            out=net(img)#put into network
            test_loss=nn.CrossEntropyLoss()(out,label).to(device)
            total_test+=test_loss#test loss, no backpropagation
            accuracy=((out.argmax(1)==label).sum()).clone().detach().cpu().numpy()# The sum of correct predictions over the length of the test set, i.e. the accuracy of correct predictions
            total_accuracy+=accuracy
    print("Loss on the training set：{}".format(total_train))
    print("Loss on the test set：{}".format(total_test))
    print("Accuracy on the test set：{:.1%}".format(total_accuracy/val_len))# Percentage accuracy, sum of correct predictions over length of test set

    torch.save(net.state_dict(),"DogandCat{}.pth".format(epoch+1))
    print("Model saved")


